{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jarvez31/Object_representation_model/blob/main/Moser_code_graph_mlp_local.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9V4wWaXFcBy5"
      },
      "source": [
        "# SETUP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBHyBKF5HoTS"
      },
      "source": [
        "### Install the extra modules"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.is_gpu_available()"
      ],
      "metadata": {
        "id": "HOxs8ALXmAjg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "684efe7a-5253-4aae-a502-e877bafd1944"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HFUY067WALhG"
      },
      "outputs": [],
      "source": [
        "###############------------------- FOR AZRA ---------------------#############\n",
        "\n",
        "# !pip install -q tensorflow-model-optimization\n",
        "# !pip install -q unrar \n",
        "# !pip install -q keras_bert\n",
        "# !pip install -q google.colab \n",
        "# !pip install -q keras-gcn\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive',force_remount=True)\n",
        "# data_fol = \"G:/.shortcut-targets-by-id/1UpJ5JeLKsI591svXPy5X8lzFEgdC3tYe/LEC_MEC_CA/\"\n",
        "# data_fol = \"G:\\.shortcut-targets-by-id\\1UpJ5JeLKsI591svXPy5X8lzFEgdC3tYe\\LEC_MEC_CA\"\n",
        "# data_fol = \"/content/drive/MyDrive/sachin_deshmukh_proj/StripedData/\"\n",
        "\n",
        "from tensorflow.keras.models import model_from_yaml, model_from_json\n",
        "from tensorflow import keras\n",
        "import pickle, shapely\n",
        "import numpy as np\n",
        "import math as mt\n",
        "import tempfile\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "from scipy import misc\n",
        "import glob, csv\n",
        "from tensorflow.keras import layers\n",
        "from shapely.geometry import box, Polygon, Point, LinearRing\n",
        "#from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten, Input, Reshape, Lambda\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, UpSampling2D, concatenate, Concatenate\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import backend as K  \n",
        "# from keras_gcn import GraphConv\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import os\n",
        "from sklearn import preprocessing\n",
        "from numpy import linalg as LA\n",
        "import pandas as pd\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from numpy import matlib\n",
        "import tensorflow_model_optimization as tfmot\n",
        "from matplotlib import cm\n",
        "main = \"Bharat_local_runs/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "_Ziyoa5hp5nb"
      },
      "outputs": [],
      "source": [
        "#@title Setup Parameters\n",
        "fol1 = \"new_graph\" #@param {type:\"string\"}\n",
        "traj1 = \"traj_obj(wo)_20k.pk1\" #@param {type:\"string\"}\n",
        "imgs = \"frames_traj(wo)_bw_20k.pk1\" #@param {type:\"string\"}\n",
        "# test_p =  7#@param {type:\"number\"}\n",
        "# img_fol = \"traj_four_objs_diffW\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Standard deviation for population code for x,y\n",
        "std_dev =  0.3 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "\n",
        "#@markdown ### Model Params\n",
        "Retrain = False #@param {type:\"boolean\"}\n",
        "Train = True #@param {type:\"boolean\"}\n",
        "Analysis = False #@param {type:\"boolean\"}\n",
        "pre_conv = True #@param {type:\"boolean\"}\n",
        "obj_pres = False #@param {type:\"boolean\"}\n",
        "stat_ful = False #@param {type:\"boolean\"}\n",
        "pi_use = \"no_osc\" #@param [\"osc\", \"no_osc\"]\n",
        "act_func = \"relu\" #@param {type:\"string\"}\n",
        "learn_rate = 0.0001 #@param {type:\"number\"}\n",
        "random_state = 42 #@param {type:\"number\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6bQ4-5q7oXV"
      },
      "source": [
        "### Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jjpuMDvo7qWT"
      },
      "outputs": [],
      "source": [
        "def rew_new(x, y, obj_boun, present=False):\n",
        "  rew = []\n",
        "  if present:\n",
        "    for i in range(len(x)):\n",
        "      kk = Point(x[i],y[i])\n",
        "      for ii in obj_boun:\n",
        "        bb = box(ii[0], ii[1], ii[2], ii[3])\n",
        "        if bb.contains(kk):\n",
        "          rew.append(1)\n",
        "        else:\n",
        "          rew.append(0)\n",
        "  else:\n",
        "    rew = [0]*len(x)\n",
        "\n",
        "  return np.asarray(rew)\n",
        "\n",
        "\n",
        "def rew(x, y, theta, objs, obj_boun, env, env_boun, present=False):\n",
        "  reward = []\n",
        "  # obj = k2\n",
        "  # obj_boun = k3\n",
        "  for i in range(len(x)): \n",
        "    if present:\n",
        "      if present:\n",
        "        for pp in range(len(objs)):\n",
        "          k2 = obj[pp]\n",
        "          k3 = obj_boun[pp]\n",
        "          if((max(k3)[0] >= x[i] >= max(k2)[0]) and (max(k2)[1] >= y[i] >= min(k2)[1]) and (90 < theta[i] < 270)):\n",
        "            reward.append(1)\n",
        "          elif((min(k3)[0] <= x[i] <= min(k2)[0]) and (max(k2)[1] >= y[i] >= min(k2)[1]) and (90>theta[i] or theta[i]>270)):\n",
        "            reward.append(1)\n",
        "          elif((min(k3)[1] <= y[i] <= min(k2)[1]) and (max(k2)[0] >= x[i] >= min(k2)[0]) and (180>theta[i]>0 )):\n",
        "            reward.append(1)\n",
        "          elif((max(k3)[1] >= y[i] >= max(k2)[1]) and (max(k2[0]) >= x[i] >= min(k2)[0]) and (360>theta[i]>180)):\n",
        "            reward.append(1)\n",
        "\n",
        "          elif((min(k3)[0] <= x[i] <= min(k2)[0]) and (max(k3)[1] >= y[i] >= max(k2)[1]) and (15>theta[i] or theta[i]>255)):\n",
        "            reward.append(1)\n",
        "          elif((min(k3)[0] <= x[i] <= min(k2)[0]) and (min(k3)[1] <= y[i] <= min(k2[1])) and (105>theta[i] or theta[i]>335)):\n",
        "            reward.append(1)\n",
        "          elif((max(k3)[0] >= x[i] >= max(k2)[0]) and (min(k3)[1] <= y[i] <= min(k2)[1]) and (195>theta[i]>75)):\n",
        "            reward.append(1)\n",
        "          elif((max(k3)[0] >= x[i] >= max(k2)[0]) and (max(k3)[1] >= y[i] >= max(k2)[1]) and (285>theta[i]>165)):\n",
        "            reward.append(1)\n",
        "\n",
        "      if len(reward) != i+1:\n",
        "        if((max(k1_env[0]) >= x[i] >= max(k1)[0]) and (90>theta[i] or theta[i]>270)):\n",
        "          reward.append(0)\n",
        "        elif((min(k1_env[0]) <= x[i] <= min(k1)[0]) and (270>theta[i]>90)):\n",
        "          reward.append(0)  \n",
        "        elif((max(k1_env[1]) >= y[i] >= max(k1)[1]) and (180>theta[i]>0)):\n",
        "          reward.append(0)\n",
        "        elif((min(k1_env)[1] <= y[i] <= min(k1)[1]) and (360>theta[i]>180)):\n",
        "          reward.append(0)\n",
        "        elif len(reward) != i+1:\n",
        "            reward.append(0)\n",
        "      \n",
        "    else:\n",
        "      if((max(k1_env[0]) >= x[i] >= max(k1)[0]) and (90>theta[i] or theta[i]>270)):\n",
        "        reward.append(0)\n",
        "      elif((min(k1_env[0]) <= x[i] <= min(k1)[0]) and (270>theta[i]>90)):\n",
        "        reward.append(0)  \n",
        "      elif((max(k1_env[1]) >= y[i] >= max(k1)[1]) and (180>theta[i]>0)):\n",
        "        reward.append(0)\n",
        "      elif((min(k1_env)[1] <= y[i] <= min(k1)[1]) and (360>theta[i]>180)):\n",
        "        reward.append(0)\n",
        "      elif len(reward) != i+1:\n",
        "          reward.append(0)\n",
        "    \n",
        "  reward = np.asarray(reward)\n",
        "  return reward\n",
        "\n",
        "\n",
        "#%% HD\n",
        "def HD(s, t):\n",
        "    with open(main + 'hd_som_wt2.pk1', 'rb') as k:\n",
        "        wt2 = pickle.load(k)\n",
        "    \n",
        "    # phase1d = np.zeros((100, 1))\n",
        "    PI2d = np.zeros((10, 10))\n",
        "    k = PI2d.shape  \n",
        "    trj_hd_resp = []\n",
        "\n",
        "    for j in range(len(s)):\n",
        "        if (j%10000 == 0):\n",
        "            print(j)\n",
        "        X1 = [mt.cos(mt.radians(t[0])), mt.sin(mt.radians(t[0]))]\n",
        "        X2 = [mt.cos(mt.radians(t[j])), mt.sin(mt.radians(t[j]))]\n",
        "        s1 = X2[0]*X1[1] - X1[0]*X2[1]\n",
        "        s2 = X2[0]*X1[0] + X1[1]*X2[1]\n",
        "        # print(s2)\n",
        "        X = [s1, s2]\n",
        "        y_p = repsom2dlinear(X, wt2)\n",
        "        trj_hd_resp.append(y_p)\n",
        "    print(\"HD response computed\")\n",
        "    return trj_hd_resp\n",
        "\n",
        "#%%\n",
        "def PI(resp, s):\n",
        "    X, Y, theta = np.zeros((100,1)), np.ones((100,1)), [[0]*100] \n",
        "    bf = 2*6*mt.pi\n",
        "    dt = np.divide(1, 100)\n",
        "    betaa, t, Xbg, Ybg = 50, 0, 1, 0\n",
        "    tarr = []\n",
        "    for ii in range(1,len(resp)):\n",
        "        if (ii%10000 == 0):\n",
        "            print(ii)\n",
        "        \n",
        "\n",
        "        y_q = resp[ii]\n",
        "        inp1d = np.reshape(np.transpose(y_q),(100,1))\n",
        "        theta_dot = [(bf + betaa * s[ii] * k[0] * 10) for k in inp1d]\n",
        "        theta_dot[:] = [x*dt for x in theta_dot]\n",
        "        theta.append([i+j for i,j in zip(theta[ii-1], theta_dot)])\n",
        "\n",
        "    theta = np.transpose(np.asarray(theta))\n",
        "    # print(theta.shape)\n",
        "    Xarr = np.cos(theta)\n",
        "    PI1d = Xarr\n",
        "    return PI1d\n",
        "\n",
        "\n",
        "def repsom2dlinear(x, wt):\n",
        "    sz_wt = list(wt.shape)\n",
        "    y = np.zeros((sz_wt[0], sz_wt[1]))\n",
        "    if(sz_wt[2] != len(x)):\n",
        "        print('Invalid input size in repsom2d()\\n')\n",
        "        return\n",
        "\n",
        "    for i in range(sz_wt[0]):\n",
        "        for j in range(sz_wt[1]):\n",
        "            v = wt[i][j].reshape(sz_wt[2], 1)    \n",
        "            # print(v)\n",
        "            y[i][j] =  np.dot(x,v)\n",
        "    return y\n",
        "\n",
        "\n",
        "def unitvec(pos_corr):\n",
        "    temp1 = np.subtract(pos_corr[1:, :], pos_corr[:-1, :])\n",
        "    temp2 = np.sqrt((temp1*temp1).sum(axis=1))\n",
        "    temp3 = temp1 / temp2.reshape(temp1.shape[0],1)\n",
        "    return temp3\n",
        "\n",
        "\n",
        "def relu(input):\n",
        "    if input > 0:\n",
        "\t    return input\n",
        "    else:\n",
        "\t    return 0\n",
        "\n",
        "\n",
        "def test_train(dat, p):\n",
        "  train_dat = np.asarray([dat[k] for k in range(len(dat)) if not k%p==0])\n",
        "  test_dat = np.asarray([dat[k] for k in range(len(dat)) if k%p==0])\n",
        "  return [train_dat, test_dat]\n",
        "\n",
        "\n",
        "def mse(data, pred_data):\n",
        "  mse_ = np.sum(np.square(data - pred_data))/len(data)\n",
        "  return mse_\n",
        "\n",
        "\n",
        "def seq_data(data, seq_len):\n",
        "  temp1 = []\n",
        "\n",
        "  for i in range(seq_len, data.shape[0]):\n",
        "    temp3 = data[i-seq_len:i]\n",
        "    temp1.append(temp3)\n",
        "  temp1 = np.asarray(temp1)\n",
        "  \n",
        "  return temp1\n",
        "\n",
        "\n",
        "class FF(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, units, **kwargs):\n",
        "        super(FF, self).__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.state_size = units\n",
        "        self.j_h = tf.keras.layers.Dense(self.units)\n",
        "        self.j_x = tf.keras.layers.Dense(self.units)\n",
        "        self.k_h = tf.keras.layers.Dense(self.units)\n",
        "        self.k_x = tf.keras.layers.Dense(self.units)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.built = True\n",
        "\n",
        "    def get_config(self):\n",
        "        return {'units': self.units}\n",
        "        \n",
        "    def call(self, inputs, states):\n",
        "        #print(\"FF:\", inputs, states)\n",
        "        prev_output = states[0]\n",
        "        j = tf.sigmoid(self.j_x(inputs) + self.j_h(prev_output))\n",
        "        k = tf.sigmoid(self.k_x(inputs) + self.k_h(prev_output))\n",
        "        output = j * (1 - prev_output) + (1 - k) * prev_output\n",
        "        return output, [output]\n",
        "\n",
        "def firing_rate_map(firposgrid, ot, firr, title):\n",
        "    res = 45\n",
        "    #firr = list(firr[0])\n",
        "    x = np.arange(-1, 1, 1/res)\n",
        "    y = np.arange(-1, 1, 1/res)\n",
        "    fx,fy = np.meshgrid(x, y)\n",
        "    firingmap = np.zeros(fx.shape)\n",
        "    #gridpoint_x = np.asarray(np.reshape(fx, np.size(fx), 1))\n",
        "    #gridpoint_y = np.asarray(np.reshape(fx, np.size(fx), 1))\n",
        "    #gridpoint = np.transpose([gridpoint_x, gridpoint_y])\n",
        "    #roundinggridpoint = np.round(gridpoint)\n",
        "    #firposround = np.round(firposgrid)\n",
        "    firingvalue = ot[firr]\n",
        "    for ii in range(len(firposgrid)):\n",
        "        q1 = np.argmin(abs(firposgrid[ii,0] - fx[1,:]))\n",
        "        q2 = np.argmin(abs(firposgrid[ii,1] - fx[1,:]))\n",
        "        firingmap[q1,q2] = firingvalue[ii]\n",
        "    firingmap = firingmap/max(np.max(firingmap),1)\n",
        "    gaussian = matlab_style_gauss2D([10, 10], 1.5)\n",
        "    spikes_smooth = scipy.signal.convolve2d(gaussian, firingmap) \n",
        "    rotated_img = ndimage.rotate(spikes_smooth, 1*270)\n",
        "    #np.rot90([spikes_smooth], 2)\n",
        "    plt.imshow(rotated_img, origin= 'upper')\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    ax=plt.gca()                            # get the axis\n",
        "    ax.set_ylim(ax.get_ylim()[::-1])        # invert the axis\n",
        "    ax.set_xlim(ax.get_xlim()[::-1])        # invert the axis\n",
        "    ax.xaxis.tick_bottom()                     # and move the X-Axis    \n",
        "    ax.set_yticklabels([])\n",
        "    ax.set_xticklabels([])\n",
        "  \n",
        "def matlab_style_gauss2D(shape,sigma):\n",
        "    \"\"\"\n",
        "    2D gaussian mask - should give the same result as MATLAB's\n",
        "    fspecial('gaussian',[shape],[sigma])\n",
        "    \"\"\"\n",
        "    m,n = [(ss-1.)/2. for ss in shape]\n",
        "    y,x = np.ogrid[-m:m+1,-n:n+1]\n",
        "    h = np.exp( -(x*x + y*y) / (2.*sigma*sigma) )\n",
        "    h[ h < np.finfo(h.dtype).eps*h.max() ] = 0\n",
        "    sumh = h.sum()\n",
        "    if sumh != 0:\n",
        "        h /= sumh\n",
        "    return h\n",
        "\n",
        "class GraphLayer(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "                 step_num=1,\n",
        "                 activation=None,\n",
        "                 **kwargs):\n",
        "        \"\"\"Initialize the layer.\n",
        "        :param step_num: Two nodes are considered as connected if they could be reached in `step_num` steps.\n",
        "        :param activation: The activation function after convolution.\n",
        "        :param kwargs: Other arguments for parent class.\n",
        "        \"\"\"\n",
        "        self.supports_masking = True\n",
        "        self.step_num = step_num\n",
        "        self.activation = keras.activations.get(activation)\n",
        "        self.supports_masking = True\n",
        "        super(GraphLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'step_num': self.step_num,\n",
        "            'activation': self.activation,\n",
        "        }\n",
        "        base_config = super(GraphLayer, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "    def _get_walked_edges(self, edges, step_num):\n",
        "        \"\"\"Get the connection graph within `step_num` steps\n",
        "        :param edges: The graph in single step.\n",
        "        :param step_num: Number of steps.\n",
        "        :return: The new graph that has the same shape with `edges`.\n",
        "        \"\"\"\n",
        "        if step_num <= 1:\n",
        "            return edges\n",
        "        deeper = self._get_walked_edges(K.batch_dot(edges, edges), step_num // 2)\n",
        "        if step_num % 2 == 1:\n",
        "            deeper += edges\n",
        "        return K.cast(K.greater(deeper, 0.0), K.floatx())\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        features, edges = inputs\n",
        "        edges = K.cast(edges, K.floatx())\n",
        "        if self.step_num > 1:\n",
        "            edges = self._get_walked_edges(edges, self.step_num)\n",
        "        outputs = self.activation(self._call(features, edges))\n",
        "        return outputs\n",
        "\n",
        "    def _call(self, features, edges):\n",
        "        raise NotImplementedError('The class is not intended to be used directly.')\n",
        "\n",
        "\n",
        "class GraphConv(GraphLayer):\n",
        "    r\"\"\"Graph convolutional layer.\n",
        "    h_i^{(t)} = \\sigma \\left ( \\frac{ G_i^T (h_i^{(t - 1)} W + b)}{\\sum G_i}  \\right )\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 units,\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 kernel_regularizer=None,\n",
        "                 kernel_constraint=None,\n",
        "                 use_bias=True,\n",
        "                 bias_initializer='zeros',\n",
        "                 bias_regularizer=None,\n",
        "                 bias_constraint=None,\n",
        "                 **kwargs):\n",
        "        \"\"\"Initialize the layer.\n",
        "        :param units: Number of new states. If the input shape is (batch_size, node_num, feature_len), then the output\n",
        "                      shape is (batch_size, node_num, units).\n",
        "        :param kernel_initializer: The initializer of the kernel weight matrix.\n",
        "        :param kernel_regularizer: The regularizer of the kernel weight matrix.\n",
        "        :param kernel_constraint:  The constraint of the kernel weight matrix.\n",
        "        :param use_bias: Whether to use bias term.\n",
        "        :param bias_initializer: The initializer of the bias vector.\n",
        "        :param bias_regularizer: The regularizer of the bias vector.\n",
        "        :param bias_constraint: The constraint of the bias vector.\n",
        "        :param kwargs: Other arguments for parent class.\n",
        "        \"\"\"\n",
        "        self.units = units\n",
        "        self.kernel_initializer = keras.initializers.get(kernel_initializer)\n",
        "        self.kernel_regularizer = keras.regularizers.get(kernel_regularizer)\n",
        "        self.kernel_constraint = keras.constraints.get(kernel_constraint)\n",
        "        self.use_bias = use_bias\n",
        "        self.bias_initializer = keras.initializers.get(bias_initializer)\n",
        "        self.bias_regularizer = keras.regularizers.get(bias_regularizer)\n",
        "        self.bias_constraint = keras.constraints.get(bias_constraint)\n",
        "\n",
        "        self.W, self.b = None, None\n",
        "        super(GraphConv, self).__init__(**kwargs)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'units': self.units,\n",
        "            'kernel_initializer': keras.initializers.serialize(self.kernel_initializer),\n",
        "            'kernel_regularizer': keras.regularizers.serialize(self.kernel_regularizer),\n",
        "            'kernel_constraint': keras.constraints.serialize(self.kernel_constraint),\n",
        "            'use_bias': self.use_bias,\n",
        "            'bias_initializer': keras.initializers.serialize(self.bias_initializer),\n",
        "            'bias_regularizer': keras.regularizers.serialize(self.bias_regularizer),\n",
        "            'bias_constraint': keras.constraints.serialize(self.bias_constraint),\n",
        "        }\n",
        "        base_config = super(GraphConv, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        feature_dim = int(input_shape[0][-1])\n",
        "        self.W = self.add_weight(\n",
        "            shape=(feature_dim, self.units),\n",
        "            initializer=self.kernel_initializer,\n",
        "            regularizer=self.kernel_regularizer,\n",
        "            constraint=self.kernel_constraint,\n",
        "            name='{}_W'.format(self.name),\n",
        "        )\n",
        "        if self.use_bias:\n",
        "            self.b = self.add_weight(\n",
        "                shape=(self.units,),\n",
        "                initializer=self.bias_initializer,\n",
        "                regularizer=self.bias_regularizer,\n",
        "                constraint=self.bias_constraint,\n",
        "                name='{}_b'.format(self.name),\n",
        "            )\n",
        "        super(GraphConv, self).build(input_shape)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0][:2] + (self.units,)\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        if mask is None:\n",
        "            mask = [None]\n",
        "        return mask[0]\n",
        "\n",
        "    def _call(self, features, edges):\n",
        "        proj = K.dot(features, self.W)\n",
        "        if self.use_bias:\n",
        "            proj += self.b\n",
        "        if self.step_num > 1:\n",
        "            edges = self._get_walked_edges(edges, self.step_num)\n",
        "        # aggr = proj/2\n",
        "        aggr = tf.math.divide((K.sum(proj, axis=1, keepdims=True) + K.epsilon()), 3)\n",
        "        # aggr = K.batch_dot(K.permute_dimensions(edges, (0, 2, 1)), proj) \\\n",
        "        #     / (K.sum(edges, axis=2, keepdims=True) + K.epsilon())\n",
        "        return features + aggr\n",
        "        # return features\n",
        "\n",
        "def obj_cent(traj_nam):\n",
        "  if traj_nam[9:12] == \"sh1\":\n",
        "    obj_c = [(0.4, 0.4)]\n",
        "    obj_c_plot = [(-0.4, -0.4), (0.4, 0.4)]\n",
        "  elif traj_nam[9:12] == \"sh2\":\n",
        "    obj_c = [(-0.4, 0.4)]\n",
        "    obj_c_plot = [(-0.4, -0.4), (0.4, 0.4), (-0.4, 0.4)]\n",
        "  elif traj_nam[9:12] == \"sh3\":\n",
        "    obj_c = [(-0.4, -0.4)]\n",
        "    obj_c_plot = [(-0.4, -0.4)]\n",
        "  elif traj_nam[9:12] == \"sh4\":\n",
        "    obj_c = [(0.4, -0.4)]\n",
        "    obj_c_plot = [(-0.4, -0.4), (0.4, 0.4), (-0.4, 0.4), (0.4, -0.4)]\n",
        "  else:\n",
        "    obj_c = [(0.0, 0.0)]\n",
        "    obj_c_plot = [(-0.4, -0.4), (0.4, 0.4), (-0.4, 0.4), (0.4, -0.4)]\n",
        "\n",
        "  return [obj_c, obj_c_plot]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uD32ZfCvcQuM"
      },
      "source": [
        "---------------------------------\n",
        "---------------------------------\n",
        "---------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9amC5ajXYev"
      },
      "source": [
        "# DATA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hU8Xl5PdU1IB"
      },
      "source": [
        "### Trajectory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ObpSNafp4iuj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "a0ee1c7b-f1d4-48d2-9726-3f0466657f25"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-5-a71c4b0d197f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfol1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtraj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraj1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'traj_obj(wo)_20k.pk1'"
          ]
        }
      ],
      "source": [
        "###--------------------- LOAD TRAJECTORY --------------------###\n",
        "\n",
        "fol = main + fol1 + \"/\"\n",
        "traj = traj1\n",
        "with open(traj, \"rb\") as f:\n",
        "    d = pickle.load(f)\n",
        "    f.close()\n",
        "locals().update(d)\n",
        "\n",
        "x = np.asarray(x)\n",
        "y = np.asarray(y)\n",
        "pos = np.column_stack((x,y))\n",
        "# x = x[:-1]\n",
        "# y = y[:-1]\n",
        "# theta = theta[:-1]\n",
        "env = [(1.0, -1.0), (1.0, 1.0), (-1.0, 1.0), (-1.0, -1.0), (1.0, -1.0)]\n",
        "# obj_c = [(0.4, 0.4)]#, (0.4, 0.4)]\n",
        "# obj_c_plot = [(-0.4, -0.4), (0.4, 0.4)]#, (-0.4, 0.4)]#, (-0.4, 0.4)]#, (0.4, -0.4), (0.0, 0.0)]\n",
        "obj_c, obj_c_plot = obj_cent(traj1)\n",
        "\n",
        "hf_sz = 0.15\n",
        "out_bound = 0.25\n",
        "obj_ver = [(c[0]-hf_sz, c[1]-hf_sz, c[0]+hf_sz, c[1]+hf_sz) for c in obj_c]\n",
        "print(obj_ver)\n",
        "obj_ver_outer = [(c[0]-hf_sz-out_bound, c[1]-hf_sz-out_bound, c[0]+hf_sz+out_bound, c[1]+hf_sz+out_bound) for c in obj_c]\n",
        "\n",
        "sq1_env = box(-1.0, -1.0, 1.0, 1.0)\n",
        "sq1 = box(-0.8, -0.8, 0.8, 0.8)\n",
        "sq2 = [box(obj_ver[j][0], obj_ver[j][1], obj_ver[j][2], obj_ver[j][3]) for j in range(len(obj_ver))]\n",
        "sq3 = [box(obj_ver_outer[k][0], obj_ver_outer[k][1], obj_ver_outer[k][2], obj_ver_outer[k][3]) for k in range(len(obj_ver_outer))]\n",
        "k1_env = list(sq1_env.exterior.coords)\n",
        "k1 = list(sq1.exterior.coords)\n",
        "k2 = [list(l.exterior.coords) for l in sq2]\n",
        "k3 = [list(ll.exterior.coords) for ll in sq3]\n",
        "\n",
        "env = [[m[0] for m in k1_env ], [m[1] for m in k1_env ]]\n",
        "obj = [[[m[0] for m in obji ], [m[1] for m in obji ]] for obji in k2]\n",
        "obj_boun = [[[m[0] for m in objbi ], [m[1] for m in objbi ]] for objbi in k3]\n",
        "# env = np.asarray(env)\n",
        "# obj = np.asarray(obj)\n",
        "\n",
        "theta = np.asarray(theta)\n",
        "theta_rad = np.radians(theta)\n",
        "print(max(theta))\n",
        "print(len(theta))\n",
        "\n",
        "## objects to do plotting that show shifting\n",
        "obj_ver_plot = [(c[0]-hf_sz, c[1]-hf_sz, c[0]+hf_sz, c[1]+hf_sz) for c in obj_c_plot]\n",
        "sq2_plot = [box(obj_ver_plot[j][0], obj_ver_plot[j][1], obj_ver_plot[j][2], obj_ver_plot[j][3]) for j in range(len(obj_ver_plot))]\n",
        "k2_plot = [list(l.exterior.coords) for l in sq2_plot]\n",
        "obj_plot = [[[m[0] for m in obji ], [m[1] for m in obji ]] for obji in k2_plot]\n",
        "\n",
        "###--------------------- CREATING GROUND TRUTH(TRAJECTORY) --------------------###\n",
        "\n",
        "# std_dev = 0.2\n",
        "# Hd_rep = np.asarray([np.sin(np.deg2rad(theta)), np.cos(np.deg2rad(theta))]).T\n",
        "# print(pos[:4,:])\n",
        "# Hd_rep = unitvec(pos)\n",
        "# print(np.sqrt((Hd_rep*Hd_rep).sum(axis=1)))\n",
        "# out = 11\n",
        "# xmat = np.matlib.repmat(x.reshape((len(x),1)),1,out)\n",
        "# ymat = np.matlib.repmat(y.reshape((len(y),1)),1,out)\n",
        "\n",
        "# xi = np.asarray(np.matlib.repmat(np.linspace(np.amin(env)-0.4,np.amax(env)+0.4,num=out, endpoint=True), len(x),1))\n",
        "# yi = np.asarray(np.matlib.repmat(np.linspace(np.amin(env)-0.4,np.amax(env)+0.4,num=out, endpoint=True), len(y),1))\n",
        "\n",
        "# x_rep = np.exp(-1*((xi-xmat)/std_dev)**2)\n",
        "# y_rep = np.exp(-1*((yi-ymat)/std_dev)**2)\n",
        "\n",
        "# rep = np.column_stack((x_rep, y_rep, Hd_rep))\n",
        "# rep2 = np.column_stack((x_rep, y_rep))\n",
        "\n",
        "# # CREATING POPULATION CODE FOR HEAD DIRECTION\n",
        "# ui_x = np.cos(np.linspace(0, 2*np.pi ,num=37, endpoint = False))\n",
        "# ui_y = np.sin(np.linspace(0, 2*np.pi ,num=37, endpoint = False))\n",
        "# ui = np.column_stack((ui_x, ui_y))\n",
        "# Hd_out_pop = np.matmul(Hd_rep, ui.T)\n",
        "\n",
        "# Hd_out_pop2 = np.maximum(Hd_out_pop, 0)\n",
        "\n",
        "# CREATE COMPLETE GROUND TRUTH\n",
        "# comp_gt = np.column_stack((rep2, Hd_out_pop))\n",
        "reward = rew_new(x, y, obj_ver_outer, present = obj_pres)\n",
        "print(len(reward))\n",
        "plt.plot(x,y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reward"
      ],
      "metadata": {
        "id": "YleTBUDD1QLu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEyeLsKmLiLV"
      },
      "outputs": [],
      "source": [
        "#print(gt)\n",
        "plt.plot(reward)\n",
        "plt.show()\n",
        "from scipy.ndimage import gaussian_filter\n",
        "import scipy\n",
        "from scipy import signal, ndimage\n",
        "#ot = predicted_output[1][:,-1,:]\n",
        "#ot = gt\n",
        "# ot = np.ndarray.flatten(encoded['val'])\n",
        "ot = reward\n",
        "print(np.sum(reward))\n",
        "print(ot.shape)\n",
        "thresh = np.min(ot)*0\n",
        "# print(thresh)\n",
        "firr = np.nonzero(ot!=thresh)\n",
        "# print(firr[0])\n",
        "#firr = np.nonzero(abs(resp_neurons[i+num])>thresh)\n",
        "firposgrid = pos[firr[0], :]\n",
        "# print(firposgrid)\n",
        "title = \"pred reward without object\"\n",
        "firing_map = firing_rate_map(firposgrid, ot, firr, title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJpZEVWv9LYh"
      },
      "source": [
        "### Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLXQIPKm10Y7"
      },
      "outputs": [],
      "source": [
        "## opening images from file\n",
        "# train_imgs = train_generator[0][0]\n",
        "# with open(data_fol+\"frames_traj(obj)_bw_20k.pk1\", 'wb') as ff:\n",
        "#     pickle.dump(train_imgs, ff)\n",
        "#     ff.close()\n",
        "    # \n",
        "with open(imgs, \"rb\") as f:\n",
        "    train_imgs = pickle.load(f)\n",
        "    f.close()\n",
        "\n",
        "# train_imgs = train_imgs[:-1]\n",
        "print(train_imgs.shape)\n",
        "\n",
        "# CREATING TEST AND TRAIN DATA-SET\n",
        "# sub_imgs = test_train(train_imgs, test_p)\n",
        "# sub_comp_gt = test_train(comp_gt, test_p)\n",
        "# comp_gt2 = np.column_stack((pos[:-1], Hd_rep))\n",
        "# sub_comp_gt2 = test_train(comp_gt2, 5)\n",
        "# print(sub_imgs[0].shape)\n",
        "# print(sub_imgs[1].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gn3BRnizJvae"
      },
      "source": [
        "### PI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "857gN0v1JzDO"
      },
      "outputs": [],
      "source": [
        "####--------------------- PI (WITHOUT OSCILLATORS)-------------------########\n",
        "print(pi_use)\n",
        "if pi_use == \"no_osc\":\n",
        "  #%%Calculating distance from starting point\n",
        "  print(\"------using PI WITHOUT oscillators-----\")\n",
        "  pos = np.column_stack((x,y))\n",
        "  a = pos[0,0] * np.ones(pos[:,0].shape)\n",
        "  b = pos[0,1] * np.ones(pos[:,1].shape)\n",
        "  origin = np.transpose(np.append([a],[b],axis=0)) #for different x,y\n",
        "\n",
        "  #origin = 0 * np.ones(pos.shape) #for same x,y\n",
        "  disp = pos - origin\n",
        "\n",
        "\n",
        "  # %% Head direciton parameters\n",
        "  n = 100\n",
        "  dth = np.divide(2*np.pi, n)\n",
        "  theta_pref = np.arange(0, 2*np.pi, dth)\n",
        "  pref_dir = np.transpose([np.cos(theta_pref), np.sin(theta_pref)])\n",
        "  print(len(pos))\n",
        "  #curr_dir = []\n",
        "  #for i in range(len(theta_rad)):\n",
        "  #    dir = np.repeat(theta_rad[i],100)\n",
        "  #    curr_dir[i].append(np.cos(dir - theta_pref))\n",
        "  hdi = preprocessing.normalize(np.cos(np.matlib.repmat(theta_pref, len(pos),1) - np.transpose((np.matlib.repmat(theta_rad[0:len(pos)],n, 1)))), norm='l2')\n",
        "\n",
        "  #%% HD responses\n",
        "  hd_resp = []\n",
        "  for i in range(len(disp)):\n",
        "      for j in range(len(pref_dir)):\n",
        "          z = np.array(disp[i])\n",
        "          dj = np.array(pref_dir[j])\n",
        "          hd_resp.append(np.dot(z,dj))\n",
        "  hd_resp = np.transpose(np.reshape(hd_resp, (len(disp),len(pref_dir))))\n",
        "\n",
        "  #%% path integraion\n",
        "  #beta = np.transpose(np.random.normal(9,2, size=(1,7)))\n",
        "  # beta = np.arange(3,4,1)\n",
        "  beta = [5]\n",
        "  pi_layer_beta = [] \n",
        "  for i in range(len(beta)):\n",
        "      #pi_layer_temp = np.concatenate((np.cos(beta[i] * hd_resp),np.sin(beta[i] * hd_resp)))\n",
        "      #pi_layer_temp = np.concatenate((beta[i] * hd_resp,beta[i] * hd_resp))\n",
        "      pi_layer_temp = np.sin(beta[i] * hd_resp)\n",
        "      #pi_layer_temp = (beta[i]* hd_resp)\n",
        "      pi_layer_beta.append((pi_layer_temp))\n",
        "  pi_layer_beta = np.asarray(pi_layer_beta)\n",
        "  pi_beta = pi_layer_beta[0]\n",
        "  for i in range(len(beta) - 1):\n",
        "      pi_beta = np.concatenate((pi_beta, pi_layer_beta[i+1]))\n",
        "  pi_lay = pi_beta.T\n",
        "  # sub_pi = test_train(pi, test_p)\n",
        "\n",
        "\n",
        "##### ---------------------------- PI (WITH OSCILLATORS) ----------------------#########\n",
        "if pi_use == \"osc\":\n",
        "  print(\"-------- using PI WITH oscillators --------\")\n",
        "  trj_hd_resp = HD(speed, theta)\n",
        "  #hd = np.asarray(trj_hd_resp)\n",
        "  PI1d = PI(trj_hd_resp, speed)\n",
        "  PI1d = np.transpose(PI1d)\n",
        "  PI1d = preprocessing.normalize(PI1d, norm='l2', axis=1)\n",
        "\n",
        "  hd_resp = [iii.T.reshape(100,1) for iii in trj_hd_resp]\n",
        "  hd_resp = np.asarray(hd_resp).reshape(len(hd_resp), hd_resp[0].shape[0])\n",
        "  hd_resp = preprocessing.normalize(hd_resp, norm='l2', axis=1)\n",
        "  num_images = PI1d.shape[0]\n",
        "  # d = {\"CAdns1\":CAdns1, \"CAdns2\":CAdns2, \"PIdns1\": PIdns1, \"PIdns2\":PIdns2, \"Lecdns\":Lecdns}\n",
        "  # with open(fol+\"PI.pk1\", 'wb') as ff:\n",
        "  #     pickle.dump(PI1d, ff)\n",
        "  #     ff.close()\n",
        "\n",
        "  # with open(fol + \"PI.pk1\", \"rb\") as f:\n",
        "  #     PI1d = pickle.load(f)\n",
        "  #     f.close()\n",
        "\n",
        "  pi_lay = PI1d\n",
        "  # sub_pi = test_train(pi, test_p)\n",
        "# pi = pi[:-1]\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# sub_imgs = train_test_split(train_imgs, test_size=0.2, random_state=random_state)\n",
        "# sub_pi = train_test_split(pi, test_size=0.2, random_state=random_state)\n",
        "# sub_comp_gt = train_test_split(comp_gt, test_size=0.2, random_state=random_state)\n",
        "# sub_r = train_test_split(reward, test_size=0.2, random_state=random_state)\n",
        "# print(sub_imgs[0].shape, sub_pi[0].shape, sub_comp_gt[0].shape, sub_r[0].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7uyGjMicT89"
      },
      "source": [
        "---------------------------------\n",
        "---------------------------------\n",
        "---------------------------------\n",
        "### Test train split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24eHpv76CDik"
      },
      "outputs": [],
      "source": [
        "# GENERATING DATA FOR LSTM\n",
        "from sklearn.model_selection import train_test_split\n",
        "seq_len = 1\n",
        "\n",
        "pi_seq = seq_data(pi_lay, seq_len)\n",
        "train_imgs_seq = seq_data(train_imgs, seq_len)\n",
        "r_seq = seq_data(reward, seq_len)\n",
        "print(train_imgs_seq.shape)\n",
        "\n",
        "sub_imgs_seq = train_test_split(train_imgs_seq, test_size=0.2, random_state=random_state)\n",
        "# sub_imgs = train_test_split(train_imgs, test_size=0.2, random_state=random_state)\n",
        "sub_pi_seq = train_test_split(pi_seq, test_size=0.2, random_state=random_state)\n",
        "# sub_pi = train_test_split(pi_lay, test_size=0.2, random_state=random_state)\n",
        "# sub_r = train_test_split(reward, test_size=0.2, random_state=random_state)\n",
        "sub_r_seq = train_test_split(r_seq, test_size=0.2, random_state=random_state)\n",
        "\n",
        "# sub_comp_gt = train_test_split(comp_gt[:-1], test_size=0.2, random_state=random_state)\n",
        "\n",
        "sub_pi_t = sub_pi_seq\n",
        "sub_imgs_t = sub_imgs_seq\n",
        "sub_r_t = sub_r_seq\n",
        "\n",
        "print(sub_pi_t[0].shape, sub_pi_t[1].shape)\n",
        "print(sub_imgs_t[0].shape, sub_imgs_t[1].shape)\n",
        "# print(sub_comp_gt[0].shape, sub_comp_gt[1].shape)\n",
        "print(sub_r_t[0].shape, sub_r_t[1].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4i4kggHa8nA"
      },
      "source": [
        "# MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrDV3pvd9pAE"
      },
      "source": [
        "### Setup Architecture"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dropout, GlobalAveragePooling2D\n",
        "from keras.regularizers import l2\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "\n",
        "#activity_regularizer=tf.keras.regularizers.l2(1)\n",
        "# strides=(2,2)                            \n",
        "if Train:\n",
        "  print(\"#########-----------------TRAINING MODEL---------------#########\")\n",
        "  act = 'relu'\n",
        "  input_img = Input(shape=(32, 32, 3), name=\"IMAGE\")\n",
        "  input_pi = Input(shape = pi_lay.shape[1], name=\"PI\")\n",
        "\n",
        "  encoder = Conv2D(8, (5, 5), padding='same', activation= act, name=\"CONV_1\")(input_img)\n",
        "  encoder = MaxPooling2D(pool_size=(2,2), padding='same', name=\"MAXPOOL_1\")(encoder)\n",
        "  encoder = Conv2D(4, (5, 5), padding='same', activation= act,name=\"CONV_2\")(encoder)\n",
        "  encoder = MaxPooling2D(pool_size=(2,2), padding='same', name=\"MAXPOOL_2\")(encoder)\n",
        "  encoder = Conv2D(2, (5, 5), padding='same', activation= act,name=\"CONV_3\")(encoder)\n",
        "  encoder = MaxPooling2D(pool_size=(2,2), padding='same', name=\"MAXPOOL_3\")(encoder)\n",
        "  flatencoder=Flatten()(encoder) \n",
        "  #flatencoder = GlobalAveragePooling2D()(encoder)\n",
        "  dense0 = Dense(50, activation = 'sigmoid', name='LEC')(flatencoder)\n",
        "  # dense1 = Dense(50, activation = act, name='LEC2')(dense0)\n",
        "  # dense0 = Dropout(0.5)(dense0)\n",
        "  dense_pi1 = Dense(50, activation= 'sigmoid', name='MEC')(input_pi)\n",
        "  # dense_pi2 = Dense(50, activation= act, name='MEC2')(dense_pi1)\n",
        "  # concat = layers.concatenate([dense1, dense_pi2])\n",
        "  dense_pi1 = layers.Reshape((1,50))(dense_pi1)\n",
        "  dense0 = layers.Reshape((1,50))(dense0)\n",
        "  data_layer = layers.concatenate([dense0, dense_pi1], axis=1)\n",
        "  print(data_layer.shape)\n",
        "  # edge_layer = layers.Input(shape=(None, None))\n",
        "  edge_layer = tf.constant(np.matlib.repmat(np.asarray([[1/3,1/3], [1/3,1/3]]), 1, 1).reshape((1,2,2)))\n",
        "  # edge_layer = tf.constant(np.asarray([[0,1], [1,0.]]).reshape((1,2,2)))\n",
        "  conv_layer = GraphConv(units=50, step_num=1,)([data_layer, edge_layer])\n",
        "  conv_layer = Dropout(0.5)(conv_layer)\n",
        "  # conv_layer0 = layers.Add()([conv_layer[:,0,:],conv_layer[:,1,:]]) \n",
        "  conv_layer0 = Flatten()(conv_layer) \n",
        "  dense1 = Dense(50, activation=act, name = 'D1')(conv_layer0)\n",
        "  # dense2 = Dense(50, activation=act, name = 'D2')(dense1)\n",
        "  # dense3 = Dense(50, activation=act, name = 'D3')(dense2)\n",
        "  # dense4 = Dense(50, activation=act, name = 'D4')(dense3)\n",
        "  # dense2 = Dense(50, activation=act, name = 'CA3')(dense1)\n",
        "  # dense0 = Dropout(0.5)(dense0)\n",
        "  #y = Lambda(lambda dense0: dense0)(dense0)\n",
        "  #z = Lambda(lambda dense0: dense0)(dense0)\n",
        "  # output1 = Dense(22, activation='sigmoid')(y)\n",
        "  #output2 = Dense(37, activation='tanh')(z)\n",
        "  output1 = Dense(1, activation='linear', name='VALUE1')(dense1)\n",
        "  # output2 = Dense(1, activation='linear', name='VALUE2')(conv_layer[:,1,:])\n",
        "  #%%\n",
        "  regressor_model = Model([input_img, input_pi], output1)\n",
        "  #regressor_model = Model([input_img,], [outputx, outputy, outputz])\n",
        "  opt = tf.keras.optimizers.Adam(learning_rate= 0.001)\n",
        "  regressor_model.compile(optimizer=opt, loss=\"mse\", )\n",
        "  regressor_model.summary()\n",
        "  # plot_model(regressor_model, to_file=fol+'Max_model1_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "tMK-cM2zILvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dropout, GlobalAveragePooling2D\n",
        "from keras.regularizers import l2\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "from tensorflow.keras.layers import Dense, RNN, LSTM, SimpleRNN\n",
        "from keras.layers import ConvLSTM2D, TimeDistributed, MaxPooling3D, Conv3D\n",
        "\n",
        "#activity_regularizer=tf.keras.regularizers.l2(1)\n",
        "# strides=(2,2)                            \n",
        "if Train and stat_ful:\n",
        "  print(\"#########-----------------TRAINING MODEL---------------#########\")\n",
        "  act = 'relu'\n",
        "\n",
        "\n",
        "  input_img = Input(batch_shape=(10,1, 32, 32, 3))\n",
        "  input_pi = Input(batch_shape=(10,1, 100))\n",
        "  #input_pi = Input(shape = (1, 100))\n",
        "  #input_img = Input(shape = (1, 32, 32, 3))\n",
        "  encoder = Conv3D(8, (1, 5, 5), padding='same', activation= act, name=\"CONV_1\")(input_img)\n",
        "  encoder = MaxPooling3D(pool_size=(1,2,2), padding='same', name=\"MAXPOOL_1\")(encoder)\n",
        "  encoder = Conv3D(4, (1, 5, 5), padding='same', activation= act,name=\"CONV_2\")(encoder)\n",
        "  encoder = MaxPooling3D(pool_size=(1,2,2), padding='same', name=\"MAXPOOL_2\")(encoder)\n",
        "  encoder = Conv3D(2, (1, 5, 5), padding='same', activation= act,name=\"CONV_3\")(encoder)\n",
        "  encoder = MaxPooling3D(pool_size=(1,2,2), padding='same', name=\"MAXPOOL_3\")(encoder)\n",
        "  flatencoder=TimeDistributed(Flatten())(encoder) \n",
        "  #print(flatencoder.shape)\n",
        "  dense0 = TimeDistributed(Dense(50, activation = 'sigmoid'), name='LEC')(flatencoder)\n",
        "  #print(dense0.shape)\n",
        "  dense_pi1 = TimeDistributed(Dense(50, activation= 'sigmoid'), name='MEC')(input_pi)\n",
        "  #print(dense_pi1.shape)\n",
        "  dense0 = layers.Reshape((1,1,50))(dense0)\n",
        "  dense_pi1 = layers.Reshape((1,1,50))(dense_pi1)\n",
        "  #print(dense0.shape, dense_pi1.shape)\n",
        "  data_layer = layers.concatenate([dense0, dense_pi1], axis=1)\n",
        "  #print(data_layer.shape)\n",
        "\n",
        "  edge_layer = tf.constant(np.matlib.repmat(np.asarray([[1/3,1/3], [1/3,1/3]]), 1, 1).reshape((1,1,2,2)))\n",
        "  # print (edge_layer.shape)\n",
        "  conv_layer = GraphConv(units=50, step_num=1,)([data_layer, edge_layer])\n",
        "  #print(\"conv_layer\", conv_layer.shape)\n",
        "  # conv_layer = layers.Reshape((1,2,50))(conv_layer)\n",
        "  print(\"conv_layer_N\", conv_layer.shape)\n",
        "  # rnn_0 = RNN(FF(25), return_sequences=True, name = \"LEC_LSTM\", stateful = True, return_state = False)(conv_layer[0,:,:])\n",
        "  # rnn_01 = RNN(FF(25), return_sequences=True, name = \"LEC_LSTM1\", stateful = True, return_state = False)(rnn_0)\n",
        "  # rnn_1= RNN(FF(25), return_sequences=True, name = \"MEC_LSTM\", stateful = True, return_state = False)(conv_layer[1,:,:])\n",
        "  # rnn_11 = RNN(FF(25), return_sequences=True, name = \"MEC_LSTM1\", stateful = True, return_state = False)(rnn_1)\n",
        "  #print(\"rnn\", rnn_0.shape),state_h11,state_c11\n",
        "  #conv_layer = Dropout(0.5)(rnn_0)\n",
        "  #temp_layer = layers.concatenate([conv_layer[:,0:1,:], rnn_0], axis = 1)\n",
        "  # temp_layer = layers.concatenate([rnn_01, rnn_11], axis = 1)\n",
        "  #print(\"temp_layer\", temp_layer.shape)\n",
        "\n",
        "  conv_layer0 = Flatten()(conv_layer)\n",
        "  #print(\"conv_layer0\", conv_layer0.shape)\n",
        "  conv_layer0 = layers.Reshape((1,100))(conv_layer0)\n",
        "  rnn = RNN(FF(50), return_sequences=False, name = \"CA3_LSTM\", stateful = True, return_state = False)(conv_layer0)\n",
        "  #rnn = RNN(FF(100), return_sequences=False, name = \"CA3_FF\", stateful = False, return_state = False)(conv_layer0)\n",
        "  # dense1 = Dense(50, activation= 'sigmoid', name='CA1')(rnn)\n",
        "  output1 = Dense(1, activation='linear', name='VALUE1')(rnn)\n",
        "\n",
        "  regressor_model = Model([input_img, input_pi], output1)\n",
        "\n",
        "  opt = tf.keras.optimizers.Adam(learning_rate= 0.0001)\n",
        "  regressor_model.compile(optimizer=opt, loss=\"mse\", )\n",
        "  regressor_model.summary()   \n",
        "\n",
        "# plot_model(regressor_model, to_file=fol+'Max_model1_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "Eojnd4exJ3v2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gxb_-QrsrIB"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSV6Sy2CPIUj"
      },
      "outputs": [],
      "source": [
        "# Train the model \n",
        "# train_imgs = (train_imgs - 0.2)*3\n",
        "\n",
        "if Train:\n",
        "  model = regressor_model\n",
        "  num_images = pos[0]-1\n",
        "  # k = np.empty(())\n",
        "  # print(k.shape)\n",
        "  # if (to_do == \"train\") or (to_do == \"both\"):\n",
        "  # for i in range(70): \n",
        "  # print(\"epoch no: \" + str(i)) \n",
        "  # edge = np.asarray([[0,1], [1,0]])\n",
        "  history = model.fit(\n",
        "            [sub_imgs_t[0], sub_pi_t[0]],\n",
        "            sub_r_t[0],\n",
        "            epochs=5,\n",
        "            batch_size=1,\n",
        "            validation_data = ([sub_imgs_t[1], sub_pi_t[1]], sub_r_t[1]),\n",
        "            shuffle = False)\n",
        "  namm = \"traj(col_obj)(wo)_newrew_mlpdepth1_bw_20k\"\n",
        "  model.save(fol+ namm +\".h5\")\n",
        "\n",
        "\n",
        "  hist_ = history.history\n",
        "  with open(fol+\"hist_\" + namm + \".pk1\", 'wb') as ff:\n",
        "      pickle.dump(hist_, ff)\n",
        "      ff.close()\n",
        "\n",
        "  kk = str(len(pos))\n",
        "  plt.plot(hist_[\"loss\"], \"-r\", label = \"loss\")\n",
        "  plt.plot(hist_[\"val_loss\"], \"--b\", label = \"val_loss\")\n",
        "  plt.legend()\n",
        "  plt.title(\"training 1 without objects \"+kk)\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXtu1WfqS8lL"
      },
      "source": [
        "### Retrain The model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_s7ZT4DTHlf"
      },
      "outputs": [],
      "source": [
        "if Retrain:  \n",
        "  print(train_imgs.shape)\n",
        "  # from keras_gcn import GraphConv\n",
        "\n",
        "  model = tf.keras.models.load_model(fol+\"traj(col_obj)(wo)_newrew_FFdepth3_bw_20k.h5\", custom_objects = {\"GraphConv\": GraphConv, \"FF\":FF})\n",
        "  opt = tf.keras.optimizers.Adam(learning_rate= 0.00002)\n",
        "  model.compile(loss='mse', optimizer=opt)\n",
        "  # model.summary()\n",
        "  \n",
        "  # Retrain the model\n",
        "  num_images = pos[0]-1\n",
        "  loss = []\n",
        "  val_loss = []\n",
        "  history = model.fit(\n",
        "            [sub_imgs_t[0], sub_pi_t[0]],\n",
        "            sub_r_t[0],\n",
        "            epochs=6,\n",
        "            batch_size=20,\n",
        "            validation_data = ([sub_imgs_t[1], sub_pi_t[1]], sub_r_t[1]),\n",
        "            shuffle = False)\n",
        "  \n",
        "  namm = \"re_traj(col_obj)(sh3f)_newrew_FFdepth3_bw_20k\"  \n",
        "  model.save(fol+ namm +\".h5\")\n",
        "\n",
        "  # save history\n",
        "  hist_ = history.history\n",
        "  with open(fol+\"hist_\" + namm + \".pk1\", 'wb') as ff:\n",
        "      pickle.dump(hist_, ff)\n",
        "      ff.close()\n",
        "\n",
        "  kk = str(len(pos))\n",
        "  plt.plot(hist_[\"loss\"], \"-r\", label = \"loss\")\n",
        "  plt.plot(hist_[\"val_loss\"], \"--b\", label = \"val_loss\")\n",
        "  plt.legend()\n",
        "  plt.title(\"training 2 with objects \"+kk)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-k5-L1PZeB3"
      },
      "source": [
        "# LAYERWISE OUTPUT ANALYSIS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsD6ib3ObekK"
      },
      "source": [
        "#### Save & load layerwise output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXUhY-B4ZiNw"
      },
      "outputs": [],
      "source": [
        "# if Analysis: \n",
        "  # from keras_gcn import GraphConv \n",
        "  # namm = []\n",
        "if (not Train) and (not Retrain):\n",
        "  namm = \"traj(col_obj)(wo)_newrew_mlpdepth1_bw_20k\"\n",
        "autoencoder_model = tf.keras.models.load_model(fol+ namm +\".h5\", custom_objects = {\"GraphConv\": GraphConv, \"FF\": FF})\n",
        "outputs  = [layer.output for layer in autoencoder_model.layers]\n",
        "\n",
        "encoded = {}\n",
        "# encoded['val'] = autoencoder_model.predict([train_imgs, pi_lay])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1iNlOhea93Q"
      },
      "outputs": [],
      "source": [
        "# GET OUTPUT FOR THE REQUIRED LAYERS\n",
        "if pre_conv:\n",
        "  import keras_bert\n",
        "  inp = autoencoder_model.input\n",
        "  layers = ['MEC', 'LEC', 'D1', 'graph_conv']\n",
        "  lim = [0.8, 0.8, 0.7, 0.8, 0.8]\n",
        "  lay_nam = layers\n",
        "  # lay_nam = ['MEC', 'LEC', 'rnn_1', 'rnn_2', 'rnn_3', 'graph_conv']\n",
        "\n",
        "  encoded_pre = {}\n",
        "\n",
        "  for i in range(len(layers)):\n",
        "    layer_output = autoencoder_model.get_layer(layers[i]).output\n",
        "    # layer_output.shape\n",
        "    functor = K.function(inp, layer_output)\n",
        "    temp1 = functor([train_imgs_seq, pi_seq])\n",
        "    # print(lay_nam[i]+ \" data is calculated.\")\n",
        "    # print(temp1.shape)\n",
        "    if layers[i] == 'graph_conv':\n",
        "      encoded_pre['graph_LEC'] = temp1[:,0,:]\n",
        "      encoded_pre['graph_MEC'] = temp1[:,1,:]\n",
        "    else:\n",
        "      encoded_pre[lay_nam[i]] = temp1\n",
        "  #     print(encoded_pre[lay_nam[i]].shape)\n",
        "  # print(encoded_pre[\"graph_LEC\"].shape)\n",
        "  # print(encoded_pre[\"graph_MEC\"].shape)\n",
        "\n",
        "\n",
        "  from matplotlib.pyplot import close\n",
        "  # outs = [encoded_pre[\"MEC\"], encoded_pre['LEC'], encoded_pre['rnn_1'], encoded_pre['rnn_2'],  encoded_pre['graph_LEC'], encoded_pre['graph_MEC']]\n",
        "  # outs = ['MEC', 'LEC', 'rnn_1', 'rnn_2', 'rnn_3', 'graph_LEC', 'graph_MEC']\n",
        "  outs = lay_nam[:-1] + ['graph_LEC', 'graph_MEC']\n",
        "  outs_n = lay_nam[:-1] + [\"gr_LEC\", \"gr_MEC\"]#, 'CA1']#, \"CA1\", \"CA3\"]\n",
        "  # outs_n = [\"MEC\", \"LEC\", 'rnn_1', 'rnn_2', 'rnn_3', \"gr_LEC\", \"gr_MEC\"]#, 'CA1']#, \"CA1\", \"CA3\"]\n",
        "  pos_out = pos\n",
        "\n",
        "  for k in range(len(outs)):\n",
        "    if outs[k] == 'rnn_1' or 'rnn_2':\n",
        "      resp_neurons = np.transpose(np.squeeze((encoded_pre[outs[k]])))\n",
        "    else:\n",
        "      resp_neurons = np.squeeze(np.transpose(encoded_pre[outs[k]]))\n",
        "    # print(resp_neurons.shape)\n",
        "    avg = np.mean(abs(resp_neurons))\n",
        "    std_dev = np.std(resp_neurons)\n",
        "    # print(avg)\n",
        "    # print(std_dev)\n",
        "    m = np.amax(resp_neurons)\n",
        "    # print(m)\n",
        "    num = 0\n",
        "    for j in range(int(np.divide(len(resp_neurons),50))):\n",
        "        onm = outs_n[k]\n",
        "        for i in range(50):\n",
        "            plt.subplot(7,8,i+1)\n",
        "            thresh = np.amax(resp_neurons[i+num]) * lim[k]\n",
        "            # thresh = 0\n",
        "            # thresh = avg + 2*std_dev\n",
        "            firr = np.nonzero(resp_neurons[i+num]>thresh)\n",
        "            firposgrid = pos_out[firr[0], :]\n",
        "            # plt.scatter(pos[:,0], pos[:,1])\n",
        "            if obj_pres:\n",
        "              for tt in range(len(obj_plot)):\n",
        "                if tt == len(obj_plot)-1:\n",
        "                  plt.plot(obj_plot[tt][0], obj_plot[tt][1], 'b')\n",
        "                else:\n",
        "                  plt.plot(obj_plot[tt][0], obj_plot[tt][1],'--', 'b')\n",
        "            plt.scatter(firposgrid[:,0], firposgrid[:,1], s = 1, color = 'red', marker='o', zorder = 5)\n",
        "            plt.plot(env[0], env[1])\n",
        "            plt.suptitle('output mesh with obj '+str(num)+ ' to '+str(num+50)+' neurons from '+ onm +' layer, threshold=' +str(lim)+\" act_func=\" + \"relu\", fontsize = 20, va = 'bottom', ha = 'center')\n",
        "\n",
        "        figure = plt.gcf() # get current figure\n",
        "        figure.set_size_inches(16, 10)\n",
        "        plt.show()\n",
        "        close()\n",
        "        num = num + 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFbf_juGtgEC"
      },
      "outputs": [],
      "source": [
        "if Analysis:\n",
        "  # GET OUTPUT FOR THE REQUIRED LAYERS\n",
        "  import keras_bert\n",
        "  # autoencoder_model = regressor_model\n",
        "  inp = autoencoder_model.input\n",
        "  layy = 'graph_conv'\n",
        "  # layers = ['dense', 'dense_1', 'dense_2', 'dense_4']\n",
        "  layers = [layy, 'CA3_LSTM']\n",
        "  # lay_nam = ['CA3', 'LEC', 'MEC', 'CA1', 'val']\n",
        "  # layers = ['LEC', 'CA']\n",
        "  lay_nam = [layy, 'CA3_LSTM']\n",
        "  # train_imgs = train_imgs[:-1]\n",
        "  # encoded = {}\n",
        "  tes = 10\n",
        "  j1 = train_imgs_seq.shape[0]//tes\n",
        "  j2 = train_imgs_seq.shape[0]%tes\n",
        "  print(j1)\n",
        "  print(j2)\n",
        "  for i in range(len(layers)):\n",
        "    layer_output = autoencoder_model.get_layer(layers[i]).output\n",
        "    layer_output\n",
        "    functor = K.function(inp, layer_output)\n",
        "    # temp1 = functor(train_imgs)\n",
        "    for jj in range(1,j1+1):\n",
        "      if jj == 1:\n",
        "        if layers[i] == layy:\n",
        "          temp1 = np.squeeze(functor([train_imgs_seq[tes*(jj-1):tes*jj], pi_seq[tes*(jj-1):tes*jj]]))\n",
        "          temp_LEC = temp1[0,:]\n",
        "          temp_MEC = temp1[1,:]\n",
        "        else:\n",
        "          temp1 = np.squeeze(functor([train_imgs_seq[tes*(jj-1):tes*jj], pi_seq[tes*(jj-1):tes*jj]]))\n",
        "\n",
        "      else:\n",
        "        if layers[i] == layy:\n",
        "          temp1 = np.squeeze(functor([train_imgs_seq[tes*(jj-1):tes*jj], pi_seq[tes*(jj-1):tes*jj]]))\n",
        "          temp_LEC = np.vstack((temp_LEC, temp1[0,:]))\n",
        "          temp_MEC = np.vstack((temp_MEC, temp1[1,:]))\n",
        "          if not jj%2000:\n",
        "            print(jj)\n",
        "        else:\n",
        "          temp1 = np.vstack((temp1, np.squeeze(functor([train_imgs_seq[tes*(jj-1):tes*jj], pi_seq[tes*(jj-1):tes*jj]]))))\n",
        "          if not jj%2000:\n",
        "            print(jj)\n",
        "    if j2!=0:\n",
        "      temp1 = np.vstack((temp1, np.squeeze(functor([train_imgs_seq[tes*j1:], pi_seq[tes*j1:]])[:,seq_len-1,:])))\n",
        "\n",
        "    print(lay_nam[i]+ \" data is calculated.\")\n",
        "    print(temp1.shape)\n",
        "    encoded[\"CA3_LSTM\"] = temp1\n",
        "    encoded[\"LEC\"] = temp_LEC\n",
        "    encoded[\"MEC\"] = temp_MEC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CFFw7U--Mfa"
      },
      "outputs": [],
      "source": [
        "plt.rcParams['figure.figsize'] = [30,5]\n",
        "# plt.plot(reward)\n",
        "# plt.plot(np.ndarray.flatten(encoded[\"val\"]))\n",
        "# # plt.plot(abs(encoded[\"MEC\"][:,2]))\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUGa9Rkzb4Y1"
      },
      "source": [
        "#### Plotting layer wise output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDzFIMSdb2tt"
      },
      "outputs": [],
      "source": [
        "if Analysis:\n",
        "  from matplotlib.pyplot import close\n",
        "  # lim = 0.5\n",
        "  outs = [encoded[\"MEC\"], encoded['LEC'], encoded['CA3_LSTM']]#, encoded['CA3']]\n",
        "  lim = [0.9, 0.9, 0.97]\n",
        "  outs_n = [\"MEC\", \"LEC\", \"CA3\"]\n",
        "  pos_out = pos\n",
        "\n",
        "  for k in range(len(outs)):\n",
        "      resp_neurons = np.transpose(outs[k])\n",
        "      avg = np.mean(abs(resp_neurons))\n",
        "      std_dev = np.std(resp_neurons)\n",
        "      print(avg)\n",
        "      print(std_dev)\n",
        "      m = np.amax(resp_neurons)\n",
        "      print(m)\n",
        "      num = 0\n",
        "      for j in range(int(np.divide(len(resp_neurons),50))):\n",
        "          onm = outs_n[k]\n",
        "          for i in range(50):\n",
        "              plt.subplot(7,8,i+1)\n",
        "              thresh = np.amax(resp_neurons[i+num]) * lim[k]\n",
        "              # thresh = 0\n",
        "              # thresh = avg + 2*std_dev\n",
        "              firr = np.nonzero(resp_neurons[i+num]>thresh)\n",
        "              firposgrid = pos_out[firr[0], :]\n",
        "              # plt.scatter(pos[:,0], pos[:,1])\n",
        "              plt.scatter(firposgrid[:,0], firposgrid[:,1], s = 1, color = 'red', marker='o', zorder = 5)\n",
        "              for tt in obj:\n",
        "                plt.plot(tt[0], tt[1])\n",
        "              plt.plot(env[0], env[1])\n",
        "              plt.suptitle('output post-conv with obj '+str(num)+ ' to '+str(num+50)+' neurons from '+ onm +' layer, threshold=' +str(lim[k])+\" act_func=\" + \"relu\", fontsize = 20, va = 'bottom', ha = 'center')\n",
        "\n",
        "          figure = plt.gcf() # get current figure\n",
        "          figure.set_size_inches(16, 10)\n",
        "          plt.show()\n",
        "          close()\n",
        "          num = num + 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hniwBbCb9v3"
      },
      "source": [
        "------------------------------\n",
        "\n",
        "\n",
        "------------------------------\n",
        "\n",
        "\n",
        "------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pylab import *\n",
        "layer_weight = autoencoder_model.get_layer(\"graph_conv\").get_weights()\n",
        "A = layer_weight[0]\n",
        "figure(1)\n",
        "imshow(A)\n",
        "colorbar()\n",
        "grid(True)\n",
        "print(np.count_nonzero(A == 0))"
      ],
      "metadata": {
        "id": "t9Pp9oSo8dBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93S_q7bnP361"
      },
      "outputs": [],
      "source": [
        "# plt.rcParams['figure.figsize'] = [30,5]\n",
        "# plt.rcParams['font.size'] = 20\n",
        "# plt.plot(encoded[\"MEC\"][:,17])\n",
        "# plt.plot(reward)\n",
        "# plt.show()\n",
        "# close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A.reshape(1,2500)\n",
        "plt.hist(A)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fR2SOholqH04"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}