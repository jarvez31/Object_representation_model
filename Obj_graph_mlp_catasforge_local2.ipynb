{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jarvez31/Object_representation_model/blob/main/Obj_graph_mlp_catasforge_local2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9V4wWaXFcBy5"
      },
      "source": [
        "# SETUP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBHyBKF5HoTS"
      },
      "source": [
        "### Install the extra modules"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%reset -f"
      ],
      "metadata": {
        "id": "t5LFoVmrmWGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
        "import tensorflow as tf\n",
        "# tf.compat.v1.disable_eager_execution()\n",
        "tf.test.is_gpu_available()"
      ],
      "metadata": {
        "id": "HOxs8ALXmAjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFUY067WALhG"
      },
      "outputs": [],
      "source": [
        "###############------------------- LOAD MODULES ---------------------#############\n",
        "\n",
        "from tensorflow.keras.models import model_from_yaml, model_from_json\n",
        "from tensorflow import keras\n",
        "from functions import *\n",
        "import pickle, shapely\n",
        "import numpy as np\n",
        "import math as mt\n",
        "import tempfile\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "from scipy import misc\n",
        "import glob, csv\n",
        "from tensorflow.keras import layers\n",
        "from shapely.geometry import box, Polygon, Point, LinearRing\n",
        "#from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten, Input, Reshape, Lambda\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, UpSampling2D, concatenate, Concatenate\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import backend as K \n",
        "from keras.regularizers import Regularizer \n",
        "# from keras_gcn import GraphConv\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import os\n",
        "from sklearn import preprocessing\n",
        "from numpy import linalg as LA\n",
        "import pandas as pd\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from numpy import matlib\n",
        "from progressbar import ProgressBar\n",
        "import tensorflow_model_optimization as tfmot\n",
        "from matplotlib import cm\n",
        "main = \" \""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_Ziyoa5hp5nb"
      },
      "outputs": [],
      "source": [
        "#@title Setup Parameters\n",
        "fol1 = \"\" #@param {type:\"string\"}\n",
        "traj1 = \"traj_obj(sh3)_20k.pk1\" #@param {type:\"string\"}\n",
        "imgs = \"frames_traj(col_obj)(sh3)_bw_20k.pk1\" #@param {type:\"string\"}\n",
        "old_model_n = \"train_0\" #@param {type:\"string\"}\n",
        "# fisher_n = \"frames_traj(wo)_bw_20k.pk1\" #@param {type:\"string\"}\n",
        "new_model_n = \"train_1\" #@param {type:\"string\"}\n",
        "epochs = 200 #@param {type:\"number\"}\n",
        "lam = 20 #@param {type:\"number\"}\n",
        "units = 200 #@param {type:\"number\"}\n",
        "# test_p =  7#@param {type:\"number\"}\n",
        "# img_fol = \"traj_four_objs_diffW\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Standard deviation for population code for x,y\n",
        "std_dev =  0.1 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "\n",
        "#@markdown ### Model Params\n",
        "Retrain = True #@param {type:\"boolean\"}\n",
        "Train = False #@param {type:\"boolean\"}\n",
        "Retrain_nocat = True #@param {type:\"boolean\"}\n",
        "# Analysis = False #@param {type:\"boolean\"}\n",
        "pre_conv = True #@param {type:\"boolean\"}\n",
        "obj_pres = True #@param {type:\"boolean\"}\n",
        "Do_fisher = False #@param {type:\"boolean\"}\n",
        "custom_loss_func = False #@param {type:\"boolean\"}\n",
        "pi_use = \"no_osc\" #@param [\"osc\", \"no_osc\"]\n",
        "act_func = \"relu\" #@param {type:\"string\"}\n",
        "learn_rate = 0.001 #@param {type:\"number\"}\n",
        "random_state = 42 #@param {type:\"number\"}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "gDKq-PiTJoaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9amC5ajXYev"
      },
      "source": [
        "# DATA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hU8Xl5PdU1IB"
      },
      "source": [
        "### Trajectory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObpSNafp4iuj"
      },
      "outputs": [],
      "source": [
        "###--------------------- LOAD TRAJECTORY --------------------###\n",
        "\n",
        "fol = main + fol1 + \"/\"\n",
        "traj = traj1\n",
        "with open(traj, \"rb\") as f:\n",
        "    d = pickle.load(f)\n",
        "    f.close()\n",
        "locals().update(d)\n",
        "\n",
        "x = np.asarray(x)\n",
        "y = np.asarray(y)\n",
        "pos = np.column_stack((x,y))\n",
        "env = [(1.0, -1.0), (1.0, 1.0), (-1.0, 1.0), (-1.0, -1.0), (1.0, -1.0)]\n",
        "obj_c, obj_c_plot = obj_cent(traj1)\n",
        "\n",
        "hf_sz = 0.15\n",
        "out_bound = 0.25\n",
        "obj_ver = [(c[0]-hf_sz, c[1]-hf_sz, c[0]+hf_sz, c[1]+hf_sz) for c in obj_c]\n",
        "print(obj_ver)\n",
        "obj_ver_outer = [(c[0]-hf_sz-out_bound, c[1]-hf_sz-out_bound, c[0]+hf_sz+out_bound, c[1]+hf_sz+out_bound) for c in obj_c]\n",
        "\n",
        "sq1_env = box(-1.0, -1.0, 1.0, 1.0)\n",
        "sq1 = box(-0.8, -0.8, 0.8, 0.8)\n",
        "sq2 = [box(obj_ver[j][0], obj_ver[j][1], obj_ver[j][2], obj_ver[j][3]) for j in range(len(obj_ver))]\n",
        "sq3 = [box(obj_ver_outer[k][0], obj_ver_outer[k][1], obj_ver_outer[k][2], obj_ver_outer[k][3]) for k in range(len(obj_ver_outer))]\n",
        "k1_env = list(sq1_env.exterior.coords)\n",
        "k1 = list(sq1.exterior.coords)\n",
        "k2 = [list(l.exterior.coords) for l in sq2]\n",
        "k3 = [list(ll.exterior.coords) for ll in sq3]\n",
        "\n",
        "env = [[m[0] for m in k1_env ], [m[1] for m in k1_env ]]\n",
        "obj = [[[m[0] for m in obji ], [m[1] for m in obji ]] for obji in k2]\n",
        "obj_boun = [[[m[0] for m in objbi ], [m[1] for m in objbi ]] for objbi in k3]\n",
        "\n",
        "theta = np.asarray(theta)\n",
        "theta_rad = np.radians(theta)\n",
        "print(max(theta))\n",
        "print(len(theta))\n",
        "\n",
        "## objects to do plotting that show shifting\n",
        "obj_ver_plot = [(c[0]-hf_sz, c[1]-hf_sz, c[0]+hf_sz, c[1]+hf_sz) for c in obj_c_plot]\n",
        "sq2_plot = [box(obj_ver_plot[j][0], obj_ver_plot[j][1], obj_ver_plot[j][2], obj_ver_plot[j][3]) for j in range(len(obj_ver_plot))]\n",
        "k2_plot = [list(l.exterior.coords) for l in sq2_plot]\n",
        "obj_plot = [[[m[0] for m in obji ], [m[1] for m in obji ]] for obji in k2_plot]\n",
        "\n",
        "# reward around the object\n",
        "reward = rew_new(x, y, obj_ver_outer, present = obj_pres)\n",
        "print(len(reward))\n",
        "plt.plot(x,y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reward & PI"
      ],
      "metadata": {
        "id": "YleTBUDD1QLu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEyeLsKmLiLV"
      },
      "outputs": [],
      "source": [
        "###------- Plot reward-------######\n",
        "plt.plot(reward)\n",
        "plt.show()\n",
        "from scipy.ndimage import gaussian_filter\n",
        "import scipy\n",
        "from scipy import signal, ndimage\n",
        "ot = reward\n",
        "print(np.sum(reward))\n",
        "thresh = np.min(ot)*0\n",
        "firr = np.nonzero(ot!=thresh)\n",
        "firposgrid = pos[firr[0], :]\n",
        "title = \"pred reward without object\"\n",
        "firing_map = firing_rate_map(firposgrid, ot, firr, title)\n",
        "plt.imshow(firing_map, origin= 'upper')\n",
        "ax=plt.gca()                            # get the axis\n",
        "ax.set_ylim(ax.get_ylim()[::-1])        # invert the axis\n",
        "ax.set_xlim(ax.get_xlim()[::-1])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "###------- Load Images -------######\n",
        "print(\"------------------------Load Images-----------------------------\")\n",
        "with open(imgs, \"rb\") as f:\n",
        "    train_imgs = pickle.load(f)\n",
        "    f.close()\n",
        "\n",
        "print(train_imgs.shape)\n",
        "\n",
        "\n",
        "#### --------- Path Integration  --------####\n",
        "print(\"------------------Calculate PI------------------------\")\n",
        "beta = [3*np.pi]\n",
        "pi_lay = PI(x, y, theta_rad, beta, pi_use)\n",
        "\n",
        "\n",
        "### ---------  Split the data  -------####\n",
        "print(\"----------------Split data in test and train----------------\")\n",
        "from sklearn.model_selection import train_test_split\n",
        "seq_len = 1\n",
        "\n",
        "pi_seq = seq_data(pi_lay, seq_len)\n",
        "train_imgs_seq = seq_data(train_imgs, seq_len)\n",
        "r_seq = seq_data(reward, seq_len)\n",
        "print(train_imgs_seq.shape)\n",
        "\n",
        "sub_imgs = train_test_split(train_imgs, test_size=0.2, random_state=random_state)\n",
        "sub_pi = train_test_split(pi_lay, test_size=0.2, random_state=random_state)\n",
        "sub_r = train_test_split(reward, test_size=0.2, random_state=random_state)\n",
        "\n",
        "\n",
        "sub_pi_t = sub_pi\n",
        "sub_imgs_t = sub_imgs\n",
        "sub_r_t = sub_r\n",
        "comp_data = [train_imgs, pi_lay]\n",
        "\n",
        "print(sub_pi_t[0].shape, sub_pi_t[1].shape)\n",
        "print(sub_imgs_t[0].shape, sub_imgs_t[1].shape)\n",
        "print(sub_r_t[0].shape, sub_r_t[1].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL"
      ],
      "metadata": {
        "id": "7VYSCYE80pcT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrDV3pvd9pAE"
      },
      "source": [
        "### Setup Architecture"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dropout, GlobalAveragePooling2D\n",
        "from keras.regularizers import l2\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "\n",
        "def custom_lr_loss(y_true, y_pred):\n",
        "  global model\n",
        "  model.optimizer.lr.assign(0.0001)\n",
        "  if y_true == 1:\n",
        "    model.optimizer.lr.assign(0.001)\n",
        "  mse = tf.keras.losses.MeanSquaredError()\n",
        "  t_loss = mse(y_true, y_pred)\n",
        "  return t_loss\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    learn_rate,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.98,\n",
        "    staircase=True)\n",
        "\n",
        "# Train the model \n",
        "if Train:\n",
        "  tf.keras.backend.clear_session()\n",
        "  model = model_arch(comp_data, nodes = units, activ = 'sigmoid', lr = lr_schedule)\n",
        "  model.summary()\n",
        "\n",
        "if Retrain:\n",
        "  opt = tf.keras.optimizers.SGD(learning_rate = learn_rate, momentum=0)\n",
        "\n",
        "  with open(fol+\"mod_dict_\" + old_model_n + \".pk1\", \"rb\") as f:\n",
        "      old_mod_dict = pickle.load(f)\n",
        "      f.close()\n",
        "\n",
        "  if Retrain_nocat:\n",
        "    keras.backend.clear_session()\n",
        "    model = model_arch(comp_data, nodes = units, activ = 'sigmoid', lr = learn_rate)\n",
        "    if custom_loss_func:\n",
        "      model.compile(optimizer = opt, loss = custom_lr_loss, )\n",
        "    else:\n",
        "      model.compile(optimizer = opt, loss = 'mse', )\n",
        "  else:\n",
        "    model = model_arch_catas(comp_data, old_mod_dict, nodes=units, lam=lam, activ = 'sigmoid', lr = learn_rate)\n",
        "    if custom_loss_func:\n",
        "      model.compile(optimizer = opt, loss = custom_lr_loss, )\n",
        "    else:\n",
        "      model.compile(optimizer = opt, loss = 'mse', )\n",
        "  \n",
        "  print(\"Loading weights from previous model\")\n",
        "  model.load_weights(fol + old_model_n +\".h5\")\n",
        "  model.summary() \n",
        "  print(model.loss)"
      ],
      "metadata": {
        "id": "tMK-cM2zILvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gxb_-QrsrIB"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if Retrain or Train:\n",
        "\n",
        "  img_ind = np.where(sub_r_t[0] == 1)\n",
        "  \n",
        "  if (model.loss == custom_lr_loss) and False:\n",
        "    train_dat = [sub_imgs_t[0][img_ind], sub_pi_t[0][img_ind]]\n",
        "    train_tar = sub_r_t[0][img_ind]\n",
        "  else:\n",
        "    train_dat = [sub_imgs_t[0], sub_pi_t[0]]\n",
        "    train_tar = sub_r_t[0]\n",
        "\n",
        "  for ii in range(epochs):\n",
        "      num_images = pos[0]-1\n",
        "      loss = []\n",
        "      val_loss = []\n",
        "      history = model.fit(\n",
        "                train_dat,\n",
        "                train_tar,\n",
        "                epochs = 1,\n",
        "                batch_size = 1 ,\n",
        "                validation_data = ([sub_imgs_t[1], sub_pi_t[1]], sub_r_t[1]),\n",
        "                shuffle = True)\n",
        "      \n",
        "      predicted_r = model.predict(comp_data)\n",
        "\n",
        "      print(ii)  \n",
        "      ot = predicted_r\n",
        "      thresh = np.min(ot)*0\n",
        "      firr = np.nonzero(ot!=thresh)\n",
        "      firposgrid = pos[firr[0], :]\n",
        "      firing_map = firing_rate_map(firposgrid, ot, firr, title)\n",
        "      plt.imshow(firing_map, origin= 'upper')\n",
        "      firing_map = firing_rate_map(firposgrid, ot, firr, title)\n",
        "      plt.imshow(firing_map, origin= 'upper')\n",
        "      plt.colorbar(ticks = np.linspace(0, 1, 5))\n",
        "      plt.clim(0,1)\n",
        "      ax=plt.gca()                            # get the axis\n",
        "      ax.set_ylim(ax.get_ylim()[::-1])        # invert the axis\n",
        "      ax.set_xlim(ax.get_xlim()[::-1])\n",
        "      plt.show()\n",
        "\n",
        "  model.save(fol+ new_model_n +\".h5\")\n",
        "  wts = model.weights\n",
        "  print(wts[-1])"
      ],
      "metadata": {
        "id": "iwtIqSByyBB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with open(fol + 'save.pk1', \"rb\") as f:\n",
        "#     d = pickle.load(f)\n",
        "#     f.close()"
      ],
      "metadata": {
        "id": "f7l7Lc32xz7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(wts)):\n",
        "  print(wts[i] == d[i])"
      ],
      "metadata": {
        "id": "28VioiNJtZsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXtu1WfqS8lL"
      },
      "source": [
        "### Fisher Compute"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if Do_fisher:\n",
        "  img_ind = np.where(sub_r_t[0] == 1)\n",
        "\n",
        "  print('Processing Fisher Information...')\n",
        "  I_new = computer_fisher(model, [sub_imgs_t[0], sub_pi_t[0]], img_ind[0])\n",
        "  print('Processing Finish!')\n",
        "  hist_ = history.history\n",
        "\n",
        "  # I_new = New_I.copy()\n",
        "  New_I = I_new.copy()\n",
        "  for j in range(len(New_I)):\n",
        "    if np.amax(New_I[j]) == 0:\n",
        "      New_I[j] = New_I[j]/(np.amax(New_I[j]) + 0.00001) \n",
        "    else:\n",
        "      New_I[j] = New_I[j]/np.amax(New_I[j])\n",
        "\n",
        "  if Retrain:\n",
        "    I = old_mod_dict[\"fisher\"]\n",
        "  if Train or Retrain_nocat:\n",
        "    I_tot = I_new\n",
        "  else: \n",
        "    I_tot = I + I_new\n",
        "\n",
        "  model_dict = {\"weights\": wts, \"fisher\": I_tot, \"history\": hist_} \n",
        "  with open(fol+\"mod_dict_\" + new_model_n + \".pk1\", 'wb') as ff:\n",
        "      pickle.dump(model_dict, ff)\n",
        "      ff.close()"
      ],
      "metadata": {
        "id": "F4G2x8Uiu3Eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if Do_fisher:\n",
        "  # if Retrain:\n",
        "  for i in range(len(I_new)):\n",
        "    # print(np.amax(New_I[i]))\n",
        "    # print(np.amax(I_new[i]))\n",
        "    # print(np.amax(I_new[i]))\n",
        "    print(I_tot[i])\n",
        "    # print(np.amax(wts[i]))"
      ],
      "metadata": {
        "id": "r3Wv8pUuIRMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-k5-L1PZeB3"
      },
      "source": [
        "# LAYERWISE OUTPUT ANALYSIS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsD6ib3ObekK"
      },
      "source": [
        "#### Save & load layerwise output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXUhY-B4ZiNw"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "autoencoder_model = model_arch(comp_data, nodes = units, activ = 'sigmoid', lr = lr_schedule)\n",
        "autoencoder_model.load_weights(fol+ new_model_n +\".h5\")\n",
        "outputs  = [layer.output for layer in autoencoder_model.layers]\n",
        "encoded = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1iNlOhea93Q"
      },
      "outputs": [],
      "source": [
        "# GET OUTPUT FOR THE REQUIRED LAYERS\n",
        "if pre_conv:\n",
        "  import keras_bert\n",
        "  inp = autoencoder_model.input\n",
        "  layers = ['MEC', 'LEC', 'D1', 'D2', 'D3', 'graph_conv']\n",
        "  lim = [0.8, 0.8, 0.9, 0.9, 0.9, 0.8, 0.8]\n",
        "  lay_nam = layers\n",
        "\n",
        "  encoded_pre = {}\n",
        "\n",
        "  for i in range(len(layers)):\n",
        "    layer_output = autoencoder_model.get_layer(layers[i]).output\n",
        "    functor = K.function(inp, layer_output)\n",
        "    temp1 = functor(comp_data)\n",
        "    if layers[i] == 'graph_conv':\n",
        "      encoded_pre['graph_LEC'] = temp1[:,0,:]\n",
        "      encoded_pre['graph_MEC'] = temp1[:,1,:]\n",
        "    else:\n",
        "      encoded_pre[lay_nam[i]] = temp1\n",
        "\n",
        "\n",
        "\n",
        "  from matplotlib.pyplot import close\n",
        "  outs = lay_nam[:-1] + ['graph_LEC', 'graph_MEC']\n",
        "  outs_n = lay_nam[:-1] + [\"gr_LEC\", \"gr_MEC\"]#, 'CA1']#, \"CA1\", \"CA3\"]\n",
        "  pos_out = pos\n",
        "\n",
        "  for k in range(len(outs)):\n",
        "    if outs[k] == 'rnn_1' or 'rnn_2':\n",
        "      resp_neurons = np.transpose(np.squeeze((encoded_pre[outs[k]])))\n",
        "    else:\n",
        "      resp_neurons = np.squeeze(np.transpose(encoded_pre[outs[k]]))\n",
        "    avg = np.mean(abs(resp_neurons))\n",
        "    std_dev = np.std(resp_neurons)\n",
        "    m = np.amax(resp_neurons)\n",
        "    num = 0\n",
        "    for j in range(int(np.divide(len(resp_neurons),50))):\n",
        "        onm = outs_n[k]\n",
        "        for i in range(50):\n",
        "            plt.subplot(7,8,i+1)\n",
        "            thresh = np.amax(resp_neurons[i+num]) * lim[k]\n",
        "            firr = np.nonzero(resp_neurons[i+num]>thresh)\n",
        "            firposgrid = pos_out[firr[0], :]\n",
        "            plt.scatter(firposgrid[:,0], firposgrid[:,1], s = 3, color = 'red', marker='o', zorder = 5)\n",
        "            if obj_pres:\n",
        "              for tt in range(len(obj_plot)):\n",
        "                if tt == len(obj_plot)-1:\n",
        "                  plt.plot(obj_plot[tt][0], obj_plot[tt][1], 'b')\n",
        "                else:\n",
        "                  plt.plot(obj_plot[tt][0], obj_plot[tt][1],'--', 'b')\n",
        "            else:\n",
        "              for tt in range(len(obj_plot)):\n",
        "                plt.plot(obj_plot[tt][0], obj_plot[tt][1],'--', 'b')\n",
        "\n",
        "            plt.plot(env[0], env[1])\n",
        "            plt.suptitle('output mesh with obj '+str(num)+ ' to '+str(num+50)+' neurons from '+ onm +' layer, threshold=' +str(lim[k])+\" act_func=\" + \"relu\", fontsize = 20, va = 'bottom', ha = 'center')\n",
        "\n",
        "        num = num + 50\n",
        "        figure = plt.gcf() # get current figure\n",
        "        figure.set_size_inches(14, 10)\n",
        "        plt.savefig(fol + onm + \"_\" + new_model_n + \"_\" + str(num), bbox_inches='tight')\n",
        "        plt.show()\n",
        "        close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CFFw7U--Mfa"
      },
      "outputs": [],
      "source": [
        "plt.rcParams['figure.figsize'] = [30,5]\n",
        "predicted_r = autoencoder_model.predict(comp_data)\n",
        "plt.plot(predicted_r, label = 'predicted_r')\n",
        "plt.plot(reward, label = 'actual_r')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(reward)\n",
        "plt.show()\n",
        "from scipy.ndimage import gaussian_filter\n",
        "import scipy\n",
        "from scipy import signal, ndimage\n",
        "#ot = predicted_output[1][:,-1,:]\n",
        "#ot = gt\n",
        "# ot = np.ndarray.flatten(encoded['val'])\n",
        "ot = predicted_r\n",
        "print(np.sum(reward))\n",
        "print(ot.shape)\n",
        "thresh = np.min(ot)*0\n",
        "# print(thresh)\n",
        "firr = np.nonzero(ot!=thresh)\n",
        "# print(firr[0])\n",
        "#firr = np.nonzero(abs(resp_neurons[i+num])>thresh)\n",
        "firposgrid = pos[firr[0], :]\n",
        "# print(firposgrid)\n",
        "title = \"pred reward without object\"\n",
        "firing_map = firing_rate_map(firposgrid, ot, firr, title)\n",
        "plt.imshow(firing_map, origin= 'upper')\n",
        "plt.colorbar()\n",
        "ax=plt.gca()                            # get the axis\n",
        "ax.set_ylim(ax.get_ylim()[::-1])        # invert the axis\n",
        "ax.set_xlim(ax.get_xlim()[::-1])"
      ],
      "metadata": {
        "id": "TR5SvyCouzqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUGa9Rkzb4Y1"
      },
      "source": [
        "#### Plotting layer wise output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hniwBbCb9v3"
      },
      "source": [
        "------------------------------\n",
        "\n",
        "\n",
        "------------------------------\n",
        "\n",
        "\n",
        "------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pylab import *\n",
        "layer_weight = autoencoder_model.get_layer(\"graph_conv\").get_weights()\n",
        "A = layer_weight[0]\n",
        "figure(1)\n",
        "imshow(A)\n",
        "colorbar()\n",
        "grid(True)\n",
        "print(np.count_nonzero(A == 0))"
      ],
      "metadata": {
        "id": "t9Pp9oSo8dBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93S_q7bnP361"
      },
      "outputs": [],
      "source": [
        "# plt.rcParams['figure.figsize'] = [30,5]\n",
        "# plt.rcParams['font.size'] = 20\n",
        "# plt.plot(encoded[\"MEC\"][:,17])\n",
        "# plt.plot(reward)\n",
        "# plt.show()\n",
        "# close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A.reshape(1,2500)\n",
        "plt.hist(A)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fR2SOholqH04"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}